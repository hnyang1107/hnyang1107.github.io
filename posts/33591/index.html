<!DOCTYPE html><html class="theme-next gemini use-motion" lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2"><link rel="stylesheet" href="/css/main.css?v=6.7.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.7.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.7.0"><link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222"><script id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"6.7.0",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!0,onmobile:!1},fancybox:!1,fastclick:!1,lazyload:!1,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="“工程能力决定下限，数学功底决定上限”"><meta name="keywords" content="机器学习,数学,cs229"><meta property="og:type" content="article"><meta property="og:title" content="机器学习中的数学基础"><meta property="og:url" content="https://yanghn.com/posts/33591/index.html"><meta property="og:site_name" content="FreeMind"><meta property="og:description" content="“工程能力决定下限，数学功底决定上限”"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://hnyang.oss-cn-shanghai.aliyuncs.com/2019-03-21-032945.jpg"><meta property="og:image" content="https://hnyang.oss-cn-shanghai.aliyuncs.com/2019-03-22-010134.jpg"><meta property="og:image" content="https://hnyang.oss-cn-shanghai.aliyuncs.com/2020-01-01-v2-e7ee6918c8da0d2664f92f1360273943_r%202.JPG"><meta property="og:image" content="https://hnyang.oss-cn-shanghai.aliyuncs.com/2020-01-06-085421.png"><meta property="og:image" content="https://hnyang.oss-cn-shanghai.aliyuncs.com/2020-01-06-114728.jpg"><meta property="og:updated_time" content="2020-01-08T15:54:32.286Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="机器学习中的数学基础"><meta name="twitter:description" content="“工程能力决定下限，数学功底决定上限”"><meta name="twitter:image" content="https://hnyang.oss-cn-shanghai.aliyuncs.com/2019-03-21-032945.jpg"><link rel="canonical" href="https://yanghn.com/posts/33591/"><script id="page.configurations">CONFIG.page={sidebar:""}</script><title>机器学习中的数学基础 | FreeMind</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">FreeMind</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">「静水深流」</h1></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签<span class="badge">10</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类<span class="badge">4</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档<span class="badge">10</span></a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i> </span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"><input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="https://yanghn.com/posts/33591/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="H.N.Yang"><meta itemprop="description" content=""><meta itemprop="image" content="/images/header.jpg"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="FreeMind"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">机器学习中的数学基础</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-03-21 02:35:40" itemprop="dateCreated datePublished" datetime="2019-03-21T02:35:40+08:00">2019-03-21</time> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-01-08 23:54:32" itemprop="dateModified" datetime="2020-01-08T23:54:32+08:00">2020-01-08</time> </span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span> </span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/posts/33591/#comments" itemprop="discussionUrl"><span class="post-meta-item-text">评论数：</span> <span class="post-comments-count valine-comment-count" data-xid="/posts/33591/" itemprop="commentCount"></span></a></span><div class="post-description">“工程能力决定下限，数学功底决定上限”</div></div></header><div class="post-body" itemprop="articleBody"><p class="description"></p><a id="more"></a><div class="note primary"><h3><span id="文章目录">文章目录</span></h3><ul><li><a href="#1-线性代数与矩阵分析">1. 线性代数与矩阵分析</a><ul><li><a href="#11-可逆矩阵与奇异矩阵">1.1 可逆矩阵与奇异矩阵</a></li><li><a href="#12-二次型与半正定矩阵">1.2 二次型与半正定矩阵</a></li><li><a href="#13-特征值与特征向量">1.3 特征值与特征向量</a></li><li><a href="#14-矩阵微分">1.4 矩阵微分</a><ul><li><a href="#141-hessian-矩阵">1.4.1 Hessian 矩阵</a></li></ul></li></ul></li><li><a href="#2-数值计算与数学分析">2. 数值计算与数学分析</a><ul><li><a href="#21-全微分与梯度">2.1 全微分与梯度</a></li><li><a href="#22-梯度下降算法">2.2 梯度下降算法</a><ul><li><a href="#221-批量梯度下降batch-gradient-descent">2.2.1 批量梯度下降(Batch Gradient Descent)</a></li><li><a href="#222-随机梯度下降stochastic-gradient-descent">2.2.2 随机梯度下降(Stochastic Gradient Descent)</a></li><li><a href="#223-小批量梯度下降mini-batch-gradient-descent">2.2.3 小批量梯度下降(Mini-Batch Gradient Descent)</a></li></ul></li></ul></li><li><a href="#3-优化理论">3. 优化理论</a><ul><li><a href="#31-拉格朗日乘子法lagrange-multipliers与-kkt-条件">3.1 拉格朗日乘子法(Lagrange multipliers)与 KKT 条件</a><ul><li><a href="#311-等式约束">3.1.1 等式约束</a></li><li><a href="#312-不等式约束与-kkt-条件">3.1.2 不等式约束与 KKT 条件</a></li><li><a href="#313-拉格朗日对偶性lagrange-duality与-slater-条件6">3.1.3 拉格朗日对偶性(Lagrange Duality)与 Slater 条件[6]</a></li></ul></li></ul></li><li><a href="#参考资料">参考资料</a></li></ul></div><h2><span id="1-线性代数与矩阵分析">1. 线性代数与矩阵分析</span></h2><h3><span id="11-可逆矩阵与奇异矩阵">1.1 可逆矩阵与奇异矩阵</span></h3><blockquote><p><strong>逆矩阵</strong>（inverse matrix）: 给定一个 $n$ 阶方阵 $\mathbf {A}$，若存在一 $n$ 阶方阵 $\mathbf {B}$ ，使得 $\mathbf{AB}=\mathbf{BA}=\mathbf{I}_n$，则称 $\mathbf{A}$ 是可逆的，且 $\mathbf {B}$ 是 $\mathbf{A}$ 的逆矩阵，记作 $\mathbf {A} ^{-1}$。</p></blockquote><p>可逆矩阵叫做 <strong>非奇异矩阵（non-singular）</strong>，在数学中，“奇异”（singular）一词用来形容破坏了某种优良性质的数学对象。对于矩阵来说，“可逆”是一个好的性质，不可逆的矩阵就称为“奇异”矩阵，可以这样按两方面简单理解，我们知道，如果一个 $n$ 阶方阵的列向量线性无关，那么这个矩阵可逆。如果一个矩阵不可逆，说明列向量线性相关，即某个列向量可以被其余列向量线性表示，而线性表示可以理解为按列向量排列的线性空间中的点具有某种“共低维（小于 $n$ 维度）空间的性质”（一个 $2\times 2$ 的矩阵不可逆表示列向量共线，一个 $3\times 3$ 方阵不可逆表示列向量共面），这样对于一个 $n$ 维空间的向量来说其实是非常 <strong>“奇异”</strong> 的，所以， <strong>不可逆矩阵叫做一个奇异矩阵。</strong><br>我们也知道，若 $A$ 不可逆，则 $|A|=0$，材料中用“体积”方法直观的解释了行列式的几何意义：</p><p><img src="https://hnyang.oss-cn-shanghai.aliyuncs.com/2019-03-21-032945.jpg" width="35%" height="50%"></p><p>上图中阴影部分的面积表示了一个二阶矩阵的一个行列式的值，若这个矩阵不可逆，两个向量线性相关，说明两个向量共线，这也说明阴影部分的面积为 $0$，故 <strong>不可逆矩阵的行列式为 $0$</strong>，而二维空间中两个向量共线是非常“奇异的”，所以 <strong>不可逆矩阵叫做一个奇异矩阵。</strong></p><h3><span id="12-二次型与半正定矩阵">1.2 二次型与半正定矩阵</span></h3><blockquote><p>对于一个方阵 $A \in \mathbb{R}^{n \times n}$ 和向量 $x \in \mathbb{R}^{n}$，标量 $x^{T} A x$ 叫做一个二次型</p></blockquote><p>按这种定义，则有：<br>$$x^{T} A x=\sum_{i=1}^{n} \sum_{j=1}^{n} A_{i j} x_{i} x_{j}$$<br>就相当于对矩阵 $A$ 所有元素都计算为二次项系数，由于对于只考虑 $i,j$ 位置的和，所以 $i,j$ 和 $j,i$ 的系数可以一分为二，故 $A$ 可以人为的构造成一个 <strong>对称矩阵</strong>，例如：</p><p>$$\begin{pmatrix}<br>x \\<br>y<br>\end{pmatrix}<br>\begin{pmatrix}<br>1 &amp; 2 \\<br>3 &amp; 4 \\<br>\end{pmatrix}<br>\begin{pmatrix}<br>x &amp; y<br>\end{pmatrix} = x^2+5xy+4y^2 = \begin{pmatrix}<br>x \\<br>y \\<br>\end{pmatrix}<br>\begin{pmatrix}<br>1 &amp; 5/2 \\<br>5/2 &amp; 4 \\<br>\end{pmatrix}<br>\begin{pmatrix}<br>x &amp; y<br>\end{pmatrix}<br>$$<br></p><div class="note warning no-icon"><ul><li>一个正定矩阵一定是一个可逆矩阵</li><li>对于矩阵$A \in \mathbb{R}^{m \times n}$，矩阵 $G=A^{T} A$ 叫做 <strong>Gram matrix</strong>，而对于一个列满秩（“竖长的矩阵”）矩阵 $A$，$x^{T} A^{T}A x$ 是一个半正定二次型，而当 $A x=0$ 时二次型等于零，由于 $A$ 列满秩，故二次型等于零 $x$ 无解，故 <strong>Gram matrix</strong> 是个正定矩阵，即是一个可逆矩阵。一般来说把 $A$ 看做训练集，训练集中样本数远大于特征数，所以 $A$ 一般是个列满秩矩阵.</li></ul></div><p></p><h3><span id="13-特征值与特征向量">1.3 特征值与特征向量</span></h3><blockquote><p>给定一个 $A \in \mathbb{R}^{n \times n}$，$$A x=\lambda x, \quad x \neq 0$$ 则称 $\lambda \in \mathbb{C}$ 为矩阵 $A$ 的特征值，$x \in \mathbb{C}^{n}$ 为对应特征值的特征向量.</p></blockquote><p>在技术上，我们一般是通过计算 $|(\lambda I-A)|=0$ 找到其特征值与特征向量，关于特征值与特征向量，有以下一些性质：<br></p><div class="note warning no-icon"><ul><li>矩阵的迹等于特征向量之和：$\operatorname{tr} A=\sum_{i=1}^{n} \lambda_{i}$</li><li>矩阵的行列式等于迹的乘积：$|A|=\prod_{i=1}^{n} \lambda_{i}$</li><li>对角矩阵 $D=\operatorname{diag}\left(d_{1}, \ldots d_{n}\right)$ 的特征值为 $d_{1}, \ldots d_{n}$.</li><li>对称矩阵的所有特征值都为实数，且其特征向量标准正交</li></ul></div><p></p><p>我们可以把所有的特征向量写在同一个矩阵 $X$ 中，可以写成：<br><img src="https://hnyang.oss-cn-shanghai.aliyuncs.com/2019-03-22-010134.jpg" width="60%" height="100%">可以得到：$$<br>A X=X \Lambda$$，若 $A$ 是对称矩阵，则 $U$ 是一个正交阵，$A=U \Lambda U^{T}$，可以得到：<br>$$ x^{T} A x=x^{T} U \Lambda U^{T} x=y^{T} \Lambda y=\sum_{i=1}^{n} \lambda_{i} y_{i}^{2}$$</p><p>而这一步就相当于二次型在配方，所以二次型的正定型取决于对称矩阵的特征值.</p><h3><span id="14-矩阵微分">1.4 矩阵微分</span></h3><blockquote><p>定义 $f : \mathbb{R}^{m \times n} \rightarrow \mathbb{R}$ 是一个矩阵到实数的一个映射，<br>$$\nabla_{A} f(A) \in \mathbb{R}^{m \times n}=\left[ \begin{array}{cccc}{\frac{\partial f(A)}{\partial A_{11}}} &amp; {\frac{\partial f(A)}{\partial A_{12}}} &amp; {\cdots} &amp; {\frac{\partial f(A)}{\partial A_{1}}} \\ {\frac{\partial f(A)}{\partial A_{21}}} &amp; {\frac{\partial f(A)}{\partial A_{22}}} &amp; {\cdots} &amp; {\frac{\partial f(A)}{\partial A_{2 n}}} \\ {\vdots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} \\ {\frac{\partial f(A)}{\partial A_{m 1}}} &amp; {\frac{\partial f(A)}{\partial A_{m 2}}} &amp; {\cdots} &amp; {\frac{\partial f(A)}{\partial A_{m n}}}\end{array}\right]$$</p></blockquote><p>对于一个一个标量求梯度输出也是一个矩阵，其维数应该等于其输入的维数，所以到底谁是输入的矩阵是非常重要的，例如对于系数矩阵$A$ 和一个实向量变元$x$，对于 $\nabla f(A x)$ 可以认为输入的维数是和 $Ax$ 相同，所以输出的梯度不是一个与 $x$ 维度相等的向量，也可以认为输入的矩阵是 $x$，所以输出应该是一个矩阵，这两种方式理解都正确，类似于微积分中 $f(ax)$ 的 导数一样，要明确对谁求导数，可以这样规定：<br></p><div class="note danger no-icon"><ul><li>如果有下标，则对下标内的矩阵求梯度，即 $\nabla_{x} f(A x)$ 对 $x$ 求梯度，输出一个向量.</li><li>若没有下标，默认对括号内求梯度，即 $\nabla f(A x)$ 输出一个维度与 $Ax$ 相等的矩阵.</li></ul></div><p></p><h4><span id="141-hessian-矩阵">1.4.1 Hessian 矩阵</span></h4><p>与梯度类似，$$\nabla_{x}^{2} f(x) \in \mathbb{R}^{n \times n}=\left[ \begin{array}{cccc}{\frac{\partial^{2} f(x)}{\partial x_{1}^{2}}} &amp; {\frac{\partial^{2} f(x)}{\partial x_{1} \partial x_{2}}} &amp; {\cdots} &amp; {\frac{\partial^{2} f(x)}{\partial x_{1} \partial x_{n}}} \\ {\frac{\partial^{2} f(x)}{\partial x_{2} \partial x_{1}}} &amp; {\frac{\partial^{2} f(x)}{\partial x_{2}^{2}}} &amp; {\cdots} &amp; {\frac{\partial^{2} f(x)}{\partial x_{2} \partial x_{n}}} \\ {\vdots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} \\ {\frac{\partial^{2} f(x)}{\partial x_{n} \partial x_{1}}} &amp; {\frac{\partial^{2} f(x)}{\partial x_{n} \partial x_{2}}} &amp; {\cdots} &amp; {\frac{\partial^{2} f(x)}{\partial x_{n}^{2}}}\end{array}\right]$$<br>这个矩阵是一个对称矩阵，不能看做梯度的梯度，因为梯度本身就是一个向量，向量没法求其梯度，几个有用的结论：<br></p><div class="note warning no-icon"><ul><li>$\nabla_{x} b^{T} x=b$</li><li>$\nabla_{x} x^{T} A x=2 A x$ 若 $A$ 是对称矩阵，特别地，$\nabla_{x} x^{T}x=2x$</li><li>$\nabla_{x} x^{T} A x=(A^{T}+A) x$ 若 $A$ 是非对称矩阵</li><li>$\nabla_{x}^{2} x^{T} A x=2 A$ 若 $A$ 是对称矩阵</li><li>$\nabla_{A}|A|=(\operatorname{adj}(A))^{T}=|A| A^{-T}$</li><li>$\nabla_{A} \log |A|=\frac{1}{|A|} \nabla_{A}|A|=A^{-1}$(用到了链式法则)</li><li>$\nabla_{A} \operatorname{tr} A B=B^{T}$</li><li>$\nabla_{A^{T}} f(A)=\left(\nabla_{A} f(A)\right)^{T}$</li><li>$\nabla_{A} \operatorname{tr} A B A^{T} C=C A B+C^{T} A B^{T}$</li></ul></div><p></p><h2><span id="2-数值计算与数学分析">2. 数值计算与数学分析</span></h2><h3><span id="21-全微分与梯度">2.1 全微分与梯度</span></h3><p>梯度(gradient)这个概念在整个机器学习和神经网络中占据重要地位，是非常重要的基础概念之一，本小节尽量利用通俗的语言去解释梯度这个概念，在理解梯度之前我们先回顾一下全微分</p><blockquote><p><strong>全微分</strong>，是多变数微积分的一个概念基本上就代表多元函数的微分，多变量函数在某点的全微分为一线性映射，通常可用矩阵或向量表示. 全微分可以看成是把单变数函数的微分推广到多变数函数上，其意义为多元函数变化量的线性逼近。例如，对于二元函数有：$$\boxed{<br>d z=f_{x} d x+f_{y} d y=\frac{\partial z}{\partial x} d x+\frac{\partial z}{\partial y} dy }$$</p></blockquote><p>初学者比较难理解这个公式怎么来的，此公式的主要思想是<strong>某点附近非常小的曲面用平面代替</strong>，如下图所示，红色平面为切平面，$A$ 点坐标为 $(x,y)$，$B$ 点坐标为 $(x+\Delta x,y+\Delta y)$，现在要比较这两点函数值 $f(x+\Delta x,y+\Delta y)-f(x,y)$ 的差值 $dz$</p><p><img src="https://hnyang.oss-cn-shanghai.aliyuncs.com/2020-01-01-v2-e7ee6918c8da0d2664f92f1360273943_r%202.JPG" width="80%" height="100%"></p><p>显然路线应该是切平面的线段 $DF$，若我们考虑 $DF$ 在 $XOZ$ 与 $YOZ$ 平面的投影 $DE$ 和 $EF$，则我们可以通过计算路径 $D\rightarrow E\rightarrow F$ 来计算 $dz$，而 $\tan{\alpha},\tan{\beta}$ 正好刻画了两个方向的偏导数，所以有<br>$$dz = |EG|+|FH| = \frac{\partial f}{\partial x}\Delta x+\frac{\partial f}{\partial y}\Delta y$$<br>不难想象，如果拓展到更高维空间，也是这种积和的形式，这种形式恰好可以理解为<strong>向量内积</strong>，把 $J:=(\frac{\partial f}{\partial x},\frac{\partial f}{\partial y})$ 定义为<strong>梯度</strong>，站在曲面上的点为 $C$, 而他所能前进的方向($XOY$平面上)为 ($\Delta x,\Delta y)$，我们只考虑方向的话，不妨设为$(\cos{\gamma},\sin{\gamma})$，由柯西不等式，$C$点在做了此决策之后能最高能够上升的高度为<br>$$\frac{\partial f}{\partial x}\cos{\gamma}+\frac{\partial f}{\partial y}\sin{\gamma}\leq \sqrt{(\frac{\partial f}{\partial x})^2+(\frac{\partial f}{\partial y})^2}$$<br>当且仅当$(\Delta x,\Delta y)=J$ 时成立，也就是说，决策者 $C$ 沿着梯度的方向走，上升最快，梯度是函数值上升的最快的方向（在投影平面上）<br></p><div class="note warning no-icon"><ul><li>梯度的方向是函数值上升的最快的方向 (在自变量的平面内)</li><li>梯度的大小决定函数值上升的速率 ($dz$)</li></ul></div><p></p><p>其实这里还蕴藏着一个几何性质，我们知道利用平面去代替这个附近的曲面，妙就妙在这个平面用分量的偏微分就可以完全刻画了，实际上，平面很重要的一个性质就是法向量，而法向量其实也可以用这两个偏微分表示：<br>$$\boldsymbol{n} = (\frac{\partial f}{\partial x},\frac{\partial f}{\partial y},-1)$$<br>这就是 <strong>$z=f(x,y)$ 在点 $(x,y)$ 处的切平面法向量</strong>，证明也是简单的：在上图中我们把 $D,E,F$ 三点坐标表示出来，可以求得向量 $\vec{DE} = \Delta x(1,0,\frac{\partial f}{\partial x})$，$\vec{EF} = \Delta y(1,0,\frac{\partial f}{\partial y})$，则 $\boldsymbol{n}\bot\vec{EF}, \vec{DE}$. 而原曲面的方程为 $g(x,y,z)=f(x,y)-z=0$ 是 $g(x,y,z)$ 分别对 $x,y,z$ 求偏导之后的结果，是一个四维空间的梯度，我们将这个结论拓展到高维空间则有：<br></p><div class="note warning no-icon"><ul><li>曲面 $g(\boldsymbol{x})=0$ 上任意一点 $\boldsymbol{x}$，该点梯度 $\nabla g(\boldsymbol{x})$ 正交于该曲面 ($\boldsymbol{x}$ 为向量)</li></ul></div><br>关于曲面和函数这两个概念有点让人混淆，现在我们可以对梯度做一个总结：<p></p><div class="note success"><p><strong>设 $\boldsymbol{x}$ 是一个 $d$ 维向量，$f$ 是一个$\mathbb{R}^{d} \rightarrow \mathbb{R}$ 的映射，则有以下结论：</strong></p><ul><li>对于 $y=f(\boldsymbol{x})$ 来说是一个函数，几何上表示的是一个 $d+1$ 维度空间的曲面（流形）（例如 $z=f(x,y)=x+y$ 实际上是一个三维平面），对这个函数对每个分量求偏导数，得到一个 $d$ 维空间的向量 $\nabla f(\boldsymbol{x})$，向量的方向表示在 $d$ 维空间上看 $f$ 上升最快的方向，分量大小表示上升速率；</li><li>$f(\boldsymbol{x})=0$ 是一个 $d$ 维的曲面，是 $y=f(\boldsymbol{x})$ 这个 $d+1$ 维流形的等值面，梯度 $\nabla f(\boldsymbol{x})$ 是这个 $d$ 维曲面的法向量.</li></ul></div><h3><span id="22-梯度下降算法">2.2 梯度下降算法</span></h3><h4><span id="221-批量梯度下降batch-gradient-descent">2.2.1 批量梯度下降(Batch Gradient Descent)</span></h4><h4><span id="222-随机梯度下降stochastic-gradient-descent">2.2.2 随机梯度下降(Stochastic Gradient Descent)</span></h4><h4><span id="223-小批量梯度下降mini-batch-gradient-descent">2.2.3 小批量梯度下降(Mini-Batch Gradient Descent)</span></h4><h2><span id="3-优化理论">3. 优化理论</span></h2><h3><span id="31-拉格朗日乘子法lagrange-multipliers与-kkt-条件">3.1 拉格朗日乘子法(Lagrange multipliers)与 KKT 条件</span></h3><blockquote><p>拉格朗日乘子法是一种寻找多元函数在其变量受到一个或多个条件的约束时的极值的方法. 这种方法可以将一个有 $d$ 个变量与 $k$ 个约束条件的最优化问题转换为一个 $d+k$ 个变量的无约束优化问题求解.</p></blockquote><h4><span id="311-等式约束">3.1.1 等式约束</span></h4><p>我们先考虑如下只带一个约束条件的优化问题：<br>$$\begin{aligned}<br>&amp;\min_{\boldsymbol{x}}f(\boldsymbol{x})\\<br>&amp;\text{ s.t. }g(\boldsymbol{x})=0\end{aligned}\tag{3.1}$$<br>其中 $\boldsymbol{x}$ 为 $d$ 维向量，那么 $f(\boldsymbol{x})$ 为 $d+1$ 维空间的曲面，$g(\boldsymbol{x})=0$ 为 $d$ 维空间的曲面. 设 $\boldsymbol{x}^{*}$ 是 最优点（自由度其实是$d$），我们有以下结论：<br></p><div class="note warning no-icon"><ul><li>约束曲面 $g(\boldsymbol{x})=0$ 上任意一点 $\boldsymbol{x}$，该点梯度 $\nabla g(\boldsymbol{x})$ 正交于该约束曲面 <strong>(2.1 小节)</strong></li><li>在最优点 $x^{*}$ 处的目标函数 $f(\boldsymbol{x})$ 的梯度 $\nabla f(\boldsymbol{x}^{*})$正交于约束曲面</li></ul></div><p></p><p>如果我们吧 $g(\boldsymbol{x})=0$ 想象成三维空间的曲面的话不好理解，因为此时 $f(x)$ 就是四维流形了 (2.1 节)，假设 $g(\boldsymbol{x})=0$ 是一个二维曲线，如下图所示<br><img src="https://hnyang.oss-cn-shanghai.aliyuncs.com/2020-01-06-085421.png" width="60%" height="100%"></p><p>如果在最优点 $x^{*}$ 处的目标函数 $f(\boldsymbol{x})$ 的梯度 $\nabla f(\boldsymbol{x}^{*})$与约束曲面不正交，说明在 $\boldsymbol{x}^{*}$ 处约束曲面上还可以沿着某个分量的其他方向使得 $f(\boldsymbol{x})$ 达到更大（梯度是 $d$ 维空间的向量，$f(\boldsymbol{x})=0$ 只是 $d$ 维空间的一部分，梯度完全有可能不在 $g(\boldsymbol{x})=0$ 内），所以一定与约束平面正交，但与 $\nabla f(\boldsymbol{x})$ 方向不一定一致，所以存在常数 $\lambda$ ，$f(\boldsymbol{x})$ 在 $\boldsymbol{x}^{*}$ 取到极值时有：<br>$$\nabla f\left(\boldsymbol{x}^{*}\right)+\lambda \nabla g\left(\boldsymbol{x}^{*}\right)=0\tag{3.2}$$<br>我们发现一个 trick：<br>$$L(\boldsymbol{x}, \lambda)=f(\boldsymbol{x})+\lambda g(\boldsymbol{x})\tag{3.3}$$<br>上式称为<strong>拉格朗日函数</strong>，对 $\boldsymbol{x}$ 的偏导数就是 (3.2)，同时这个函数对 $\lambda$ 的偏导数正好就是约束条件，那么我们就可以把这个等式约束融合在目标函数里而变成无约束的优化问题.</p><h4><span id="312-不等式约束与-kkt-条件">3.1.2 不等式约束与 KKT 条件</span></h4><p>不等式约束稍微比等式约束稍微复杂一点，我们考虑两种情况：</p><ul><li>$f(\boldsymbol{x})$ 在边界上取到极值，此时对应等式约束的情况，即 $g(\boldsymbol{x}^{*})=0$</li><li>$f(\boldsymbol{x})$ 在内部取到极值，此时对应 $g(\boldsymbol{x}^{*})&lt;0$ 的情况</li></ul><p>对于情况一，我们回到了 (3.2) 式，但注意，此时的 $\lambda&gt;0$，这是因为： $\nabla g(\boldsymbol{x})$ 是 $y=g(\boldsymbol{x})$ 上升最快的方向，相对于此时 $\nabla g(\boldsymbol{x})=0$ 来说，肯定指向 $g(\boldsymbol{x})&gt;0$ 的方向，所以指向外部；而我们现在求的是 $f$ 的极小值，内部的点比外部要大，$\nabla g(\boldsymbol{x})$ 肯定指向内部，所以 $\lambda&gt;0$，这时候只需要<br>$$\begin{aligned}<br>&amp;\nabla f\left(\boldsymbol{x}^{*}\right)+\lambda \nabla g\left(\boldsymbol{x}^{*}\right)=0\\<br>&amp;g(\boldsymbol{x})=0\\<br>&amp;\lambda&gt;0\end{aligned}\tag{3.4}$$<br>对于情况二，解在内部约束条件就是无效的，因为在内部的解不管朝什么方向移动一小步都仍然满足约束条件，永远达不到边界，所以只需要 $\nabla f(\boldsymbol{x})=0$ 即可，这等价于(3.2)式 $\lambda=0$，将两种情况一合并在一起得到 $\lambda g(\boldsymbol{x})=0$</p><p>$$\left\lbrace\begin{array}{l}<br>{g(\boldsymbol{x}) \leqslant 0} \\<br>{\lambda \geqslant 0} \quad \quad \quad \quad \text{对偶可行性}\\<br>{\lambda g(\boldsymbol{x})=0} \quad \quad \text{互补松弛性}<br>\end{array}\right.\tag{3.5}$$</p><p>上式称为 KKT 条件(<a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions#Regularity_conditions_(or_constraint_qualifications" target="_blank" rel="noopener">Karush–Kuhn–Tucker conditions</a>).</p><p><img src="https://hnyang.oss-cn-shanghai.aliyuncs.com/2020-01-06-114728.jpg" width="50%" height="100%"></p><blockquote><p>上面两种情况可以用上面这张图片表示，图为函数的等值线与约束曲线 $g(\boldsymbol{x})$ 的关系，当 $\boldsymbol{x}^{*}$ 在内部时满足 $\nabla f(\boldsymbol{x})=0$，当 $\boldsymbol{x}^{*}$ 在外部时当且仅当边界与等值线相切的时候取到最大值，因为等高线始终与 $\nabla f(\boldsymbol{x})$ 正交.</p></blockquote><p>(3.5) 的结果可推广至多个约束等式与约束不等式的情况。考虑标准约束优化问题<br>$$\begin{array}{ll}<br>{\min} &amp; {f(\boldsymbol{x})} \\<br>{\text { s.t. }} &amp; {h_{i}(\boldsymbol{x})=0 \quad(i=1, \ldots, m)} \\<br>{} &amp; {g_{j}(\boldsymbol{x}) \leqslant 0 \quad(j=1, \ldots, p)}<br>\end{array}\tag{3.6}$$<br>引入拉格朗日乘子 $\boldsymbol{\lambda}$，$\boldsymbol{\mu}$<br>$$L(\boldsymbol{x}, \boldsymbol{\lambda}, \boldsymbol{\mu})=f(\boldsymbol{x})+\sum_{i=1}^{m} \lambda_{i} h_{i}(\boldsymbol{x})+\sum_{j=1}^{p} \mu_{j} g_{j}(\boldsymbol{x})\tag{3.7}$$<br>由不等式引入的 KKT 条件为：<br>$$\left\lbrace\begin{array}{l}<br>{g_{j}(\boldsymbol{x}) \leqslant 0} \\<br>{\mu_{j} \geqslant 0}\\<br>{\mu_{j} g_{j}(\boldsymbol{x})=0}<br>\end{array}\right.\tag{3.8}$$</p><h4><span id="313-拉格朗日对偶性lagrange-duality与-slater-条件6">3.1.3 拉格朗日对偶性(Lagrange Duality)与 Slater 条件[6]</span></h4><p>我们重新考虑 (3.6) 这个式子，任意一个带约束的优化都可以写成这样的形式（若求最大可以在目标函数前加负号转化为求最小）. 若 $h_1,h_2,\ldots,h_m$ 和 $f$ 都是<a href="http://en.wikipedia.org/wiki/Convex_function" target="_blank" rel="noopener">凸函数</a> ，并且 $g_1,g_2,\ldots,g_p$ 全都是仿射函数（就是形如 $Ax+b$ 的形式），那么这个问题就叫做<a href="https://en.wikipedia.org/wiki/Convex_optimization" target="_blank" rel="noopener">凸优化</a>(Convex optimization)问题. 凸优化问题有许多优良的性质，例如它的极值是唯一的。不过，这里我们并没有假定需要处理的优化问题是一个凸优化问题. 对于 (3.7) 我们假设<br>$$z(\boldsymbol{x})=\max_{\boldsymbol{\mu}\succeq 0, \boldsymbol{\lambda}}L(\boldsymbol{x}, \boldsymbol{\lambda}, \boldsymbol{\mu})\tag{3.9}$$这里 $\boldsymbol{\mu}\succeq 0$ 理解为向量 $\boldsymbol{\lambda}$ 的每一个元素都非负即可，上式是一个关于 $\boldsymbol{x}$ 的函数，我们有以下结论，当 $\boldsymbol{x}$ 满足(3.6)的约束时，则有<br>$$f(\boldsymbol{x})=z(\boldsymbol{x})\tag{3.10}$$ 这也是容易验证的，满足(3.6)的约束时，$h(\boldsymbol{x}_{i})=0$，注意到 $\mu_{j}g(\boldsymbol{x}_{j})$ 的非正性，最大化 $z(x)$ 时显然 $\mu_{i}g(\boldsymbol{x}_{j})=0$，所以就证明了上面的式子，这样一来，原始的带约束的优化问题(3.6)其实等价于如下的无约束优化问题：<br>$$\min_{\boldsymbol{x}}z(\boldsymbol{x})=\min_{\boldsymbol{x}}\max_{\boldsymbol{\mu}\succeq 0, \boldsymbol{\lambda}}L(\boldsymbol{x}, \boldsymbol{\lambda}, \boldsymbol{\mu})\tag{3.11}$$ 我们可以把 $\boldsymbol{x}$ 所在的整个空间分为两部分：一部分是满足约束条件 $P_1$，另一部分是不满足约束条件的 $P_2$：</p><ul><li>当 $\boldsymbol{x} \in P_1$ 时由 3.10 可知 $\min_{\boldsymbol{x}}f(\boldsymbol{x}) = \min_{\boldsymbol{x}}z(\boldsymbol{x})$</li><li>当 $\boldsymbol{x} \in P_2$ 时，$\max_{\boldsymbol{\mu}\succeq 0, \boldsymbol{\lambda}}L(\boldsymbol{x}, \boldsymbol{\lambda}, \boldsymbol{\mu})=\max_{\boldsymbol{\mu}\succeq 0, \boldsymbol{\lambda}}(f(\boldsymbol{x})+\infty)$，因为 $h$ 和 $g$ 在约束条件之外 $\lambda$ 和 $\mu$ 总能改变其值使得 $\sum_{i=1}^{m} \lambda_{i} h_{i}(\boldsymbol{x})+\sum_{j=1}^{p} \mu_{j} g_{j}(\boldsymbol{x})=+\infty$</li></ul><p>综合这两点，考虑$\boldsymbol{x}$ 的整个空间上要达到最小，$P_2$ 自动就被排除在外，所以最小化 $z(\boldsymbol{x})$ 就变成了目标函数为(3.11)的无约束规划（这里无约束是相对 $\boldsymbol{x}$ 来说，$\boldsymbol{\mu}$ 还是有约束）. 而这样写只是对原始式子做了一个变换，把约束条件融合在目标函数里，原问题没有发生本质变化，我们把 (3.11) 无约束目标规划成为原问题(primal problem)，是最小化 $\boldsymbol{x}$. 相对应的还有一个对偶问题(dual problem)，其形式非常类似，只是把 $\min$ 和 $\max$ 交换了一下：<br>$$\max_{\boldsymbol{\mu}\succeq 0, \boldsymbol{\lambda}}g(\boldsymbol{\mu},\boldsymbol{\lambda})=\max_{\boldsymbol{\mu}\succeq 0, \boldsymbol{\lambda}}\min_{\boldsymbol{x}}L(\boldsymbol{x}, \boldsymbol{\lambda}, \boldsymbol{\mu})\tag{3.12}$$ 交换之后的 dual problem 在最大化 $\boldsymbol{\mu},\boldsymbol{\lambda}$， 这和原来的 primal problem 并不相等，直观地，我们可以这样来理解：中国乒乓球国家队最差的选手比国外乒乓球最好的选手要强. 换句话说，如果 primal problem 的最小值记为 $p^{*}$，dual problem 的最大值记为 $d^{*}$，则有$$d^{*}\leqslant p^{*}\tag{3.13}$$这个性质叫做 weak duality ，对于所有的优化问题都成立。其中 $p^{*}−d^{*}$ 被称作 duality gap. 需要注意的是，无论 primal problem 是什么形式，dual problem 总是一个 <strong>convex optimization</strong> 的问题[7]：$$\begin{array}{ll}<br>{\max} &amp; g(\boldsymbol{\mu},\boldsymbol{\lambda}) \\<br>{\text { s.t. }} &amp; \boldsymbol{\mu}\succeq 0<br>\end{array}\tag{3.14}$$ 它的极值是唯一的（如果存在的话），并且有现成的软件包可以对凸优化问题进行求解（虽然求解 general 的 convex optimization 实际上是很慢并且只能求解规模较小的问题的）。这样一来，对于那些难以求解的 primal problem （比如，甚至可以是 NP 问题），我们可以通过找出它的 dual problem ，通过优化这个 dual problem 来得到原始问题的一个下界估计。或者说我们甚至都不用去优化这个 dual problem ，而是（通过某些方法，例如随机）选取一些 $\lambda\geqslant 0$ 和 $\mu$ ，带到 $g(\boldsymbol{\mu},\boldsymbol{\lambda})$ 中，这样也会得到一些下界（只不过不一定是最大的那个下界而已）。当然要选 $\boldsymbol{\mu}$ 和 $\boldsymbol{\lambda}$ 也并不是总是“随机选”那么容易，根据具体问题，有时候选出来的 $\boldsymbol{\lambda}$ 和 $\boldsymbol{\mu}$ 带入 $g$ 会得到 $−\infty$ ，这虽然是一个完全合法的下界，然而却并没有给我们带来任何有用的信息.<br>故事到这里还没有结束，既然有 weak duality ，显然就会有 strong duality. 所谓 strong duality ，就是$$d^{*}\leqslant p^{*}\tag{3.14}$$这是一个很好的性质，strong duality 成立的情况下，我们可以通过求解 dual problem 来优化 primal problem ，在 SVM 中我们就是这样做的。当然并不是所有的问题都能满足 strong duality ，在讲 SVM 的时候我们直接假定了 strong duality 的成立，这里我们就来提一下 strong duality 成立的条件。不过，这个问题是一个很复杂的问题，这里直接给出结论：<br></p><div class="note info no-icon"><p><strong>Slater 条件</strong><br>Slater 条件是指存在严格满足约束条件的点 $x$ ，这里的“严格”是指 $g_{i}(x)\leqslant 0$ 中的“小于或等于号”要严格取到“小于号”，亦即，存在 $x$ 满足:$$\begin{array}{ll}<br>{g_{i}(x)&lt;0} &amp; {i=1, \ldots, m} \\<br>{h_{i}(x)=0} &amp; {i=1, \ldots, p}<br>\end{array}\tag{3.15}$$如果原始问题是 Convex 的并且满足 Slater 条件的话，那么 strong duality 成立</p></div><br>需要注意的是，这里只是指出了 strong duality 成立的一种情况，而并不是唯一情况。例如，对于某些非 convex optimization 的问题，strong duality 也成立. 在 <a href="https://yanghn.com/posts/33807/#22-lagrange-duality">SVM 的 primal problem</a> 中是一个 QP（QP 是凸优化问题的一种特殊情况），而 Slater 条件实际上在这里就等价于是存在这样的一个超平面将数据分隔开来，亦即是“数据是可分的”. 所以在 Slater 条件成立的情况下用对偶问题可以求出极值点.<br>对偶问题和 KKT 条件还有一个定理，即若对偶问题和原问题有相同的解，则满足 KKT 条件（$f,g$ 为凸，$h$ 为仿射函数的情况下）. 我们结合 Slater 定理可以得到<br><div class="note success no-icon"><p>若 $f,g$ 为凸，$h$ 为仿射函数，$x$ 和 $\mu,\lambda$ 分别是原问题和对偶问题的解</p><ul><li>存在严格小于$\Longleftrightarrow$ $x$ 和 $\mu,\lambda$ 满足 KKT 条件(3.8)</li></ul></div><p></p><p><mark>TODO:文档过长要拆分<mark></mark></mark></p><h2><span id="参考资料">参考资料</span></h2><p><strong>[1]</strong> Mathematics For Machine Learning, Marc Peter Deisenroth, A Aldo Faisal, and Cheng Soon Ong, <em>Cambridge University Press</em>, 2020 <a href="https://hnyang.oss-cn-shanghai.aliyuncs.com/mml-book_printed.pdf" target="_blank"><i></i><span>[PDF]</span></a><br><strong>[2]</strong> Linear Algebra Review and Reference, Zico Kolter, <em>CS224 material</em>, 2015 <a href="https://hnyang.oss-cn-shanghai.aliyuncs.com/Linear%20Algebra%20Review%20and%20Reference.pdf" target="_blank"><i></i><span>[PDF]</span></a><br><strong>[3]</strong> 矩阵分析与应用, 张贤达, <em>清华大学出版社</em>, 第二版, 2013 <a href="http://hnyang.oss-cn-shanghai.aliyuncs.com/%E3%80%8A%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89%E5%BC%A0%E8%B4%A4%E8%BE%BE%E3%80%8BPDF.pdf" target="_blank"><i></i><span>[PDF]</span></a><br><strong>[4]</strong> Mathematics for Data Science, Ibrahim Sharaf ElDen, <em>towardsdatascience.com</em>, 2019 [<a href="https://towardsdatascience.com/mathematics-for-data-science-e53939ee8306" target="_blank" rel="noopener">Link</a>]<br><strong>[5]</strong> 机器学习 (附录), 周志华，<em>清华大学出版社</em>, 第一版, 2016 [<a href="https://hnyang.oss-cn-shanghai.aliyuncs.com/2020-01-05-%E5%91%A8%E5%BF%97%E5%8D%8E-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.pdf" target="_blank" rel="noopener">Link</a>]<br><strong>[6]</strong> 支持向量机：Duality, 张驰原, <em>pluskid.org</em>, 2010, [<a href="http://blog.pluskid.org/?p=702&amp;cpage=1#comment-7347" target="_blank" rel="noopener">Link</a>]<br><strong>[7]</strong> Stephen Boyd, et al. Convex Optimization, Cambridge university press, 2004. [<a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf" target="_blank" rel="noopener">Link</a>]</p></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>H.N.Yang</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://yanghn.com/posts/33591/" title="机器学习中的数学基础">https://yanghn.com/posts/33591/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/机器学习/" rel="tag"><i class="fa fa-tag"></i> 机器学习</a> <a href="/tags/数学/" rel="tag"><i class="fa fa-tag"></i> 数学</a> <a href="/tags/cs229/" rel="tag"><i class="fa fa-tag"></i> cs229</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/posts/41333/" rel="next" title="线性模型"><i class="fa fa-chevron-left"></i> 线性模型</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/posts/47671/" rel="prev" title="Python 进阶笔记">Python 进阶笔记 <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div></div><div class="comments" id="comments"></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><div class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/header.jpg" alt="H.N.Yang"><p class="site-author-name" itemprop="name">H.N.Yang</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">4</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">10</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/hnyang1107" title="GitHub &rarr; https://github.com/hnyang1107" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:haonyang@gamil.com" title="E-Mail &rarr; mailto:haonyang@gamil.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a></span></div></div></div><div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-text">1. 线性代数与矩阵分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-text">2. 数值计算与数学分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-text">3. 优化理论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-text">参考资料</span></a></li></ol></div></div></div></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright"><a href="http://beian.miit.gov.cn/" rel="noopener" target="_blank">赣ICP备19011924号 </a>&copy; <span itemprop="copyrightYear">2020</span> <span class="with-love" id="animate"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">H.N.Yang</span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script>"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script color="0,0,0" opacity="0.5" zindex="-1" count="199" src="/lib/canvas-nest/canvas-nest-nomobile.min.js"></script><script src="/lib/jquery/index.js?v=2.1.3"></script><script src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script src="/js/src/utils.js?v=6.7.0"></script><script src="/js/src/motion.js?v=6.7.0"></script><script src="/js/src/affix.js?v=6.7.0"></script><script src="/js/src/schemes/pisces.js?v=6.7.0"></script><script src="/js/src/scrollspy.js?v=6.7.0"></script><script src="/js/src/post-details.js?v=6.7.0"></script><script src="/js/src/bootstrap.js?v=6.7.0"></script><script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script><script src="//unpkg.com/valine/dist/Valine.min.js"></script><script>var GUEST=["nick","mail","link"],guest="nick,mail,link";guest=guest.split(",").filter(function(e){return-1<GUEST.indexOf(e)}),new Valine({el:"#comments",verify:!1,notify:!0,appId:"BLkE0wdwFsV3AsqLlBxjGn9t-gzGzoHsz",appKey:"3DRdGHieM8RANLx4raFf1J03",placeholder:"输入邮箱可以收到后续回复，支持 Markdown 语法.",avatar:"retro",meta:guest,pageSize:"1",visitor:!1});var infoEle=document.querySelector("#comments .info");infoEle&&infoEle.childNodes&&0<infoEle.childNodes.length&&infoEle.childNodes.forEach(function(e){e.parentNode.removeChild(e)})</script><script>// Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: "AMS"
      }
    }
  });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
      for (i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });</script><script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><style>.MathJax_Display{overflow:auto hidden}</style></body></html>